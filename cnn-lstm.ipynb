{"cells":[{"cell_type":"code","source":["from numpy import mean\n","from numpy import std\n","from numpy import dstack\n","from pandas import read_csv\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, Dropout, LSTM, TimeDistributed, Conv1D, MaxPooling1D\n","from keras.utils import to_categorical\n","from keras.optimizers import Adam"],"metadata":{"id":"x04X16ZrTkfc","executionInfo":{"status":"ok","timestamp":1697309070042,"user_tz":-180,"elapsed":6,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"execution_count":162,"outputs":[]},{"cell_type":"code","execution_count":163,"metadata":{"id":"FcDsa1dmf6an","executionInfo":{"status":"ok","timestamp":1697309070042,"user_tz":-180,"elapsed":5,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"outputs":[],"source":["# drive path\n","drive = '/content/drive/My Drive/Colab Notebooks/HAR'\n","\n","# local path\n","# local = 'G:/My Drive/Colab Notebooks/HAR'\n","local = 'G:/HAR'\n","\n","hapt = '/HAPT Dataset'       # Human Activity Postural Transitions data set\n","har = '/UCI HAR Dataset'      # Human Activity Recognition data set\n","\n","path_drive = drive + har\n","path_local = local + har"]},{"cell_type":"code","source":["using_drive = 1\n","\n","if using_drive == 1:\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  path = path_drive\n","else:\n","  path = path_local"],"metadata":{"id":"ZkEbaQgbWd0i","executionInfo":{"status":"ok","timestamp":1697309074321,"user_tz":-180,"elapsed":4284,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4ea86d92-8b42-4eb2-e54e-3bd707ee0b74"},"execution_count":164,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Gravitational acceleration data files for x, y and z axes: `total_acc_x_train.txt`, `total_acc_y_train.txt` , `total_acc_z_train.txt`.<br>\n","Body acceleration data files for x, y and z axes: `body_acc_x_train.txt`, `body_acc_y_train.txt`, `body_acc_z_train.txt`.<br>\n","Body gyroscope data files for x, y and z axes: `body_gyro_x_train.txt`,\n","`body_gyro_y_train.txt`, `body_gyro_z_train.txt`.<br>\n","The structure is mirrored in the test directory."],"metadata":{"id":"SUg9w7CnY-Cw"}},{"cell_type":"code","source":["# load a single file as a numpy array\n","def load_file(filepath):\n","  dataframe = read_csv(filepath, header=None, delim_whitespace=True, encoding='utf-8', encoding_errors='ignore')\n","  return dataframe.values\n","\n","# load a list of files, such as x, y, z data for a given variable\n","def load_group(filenames, prefix=''):\n","  loaded = list()\n","  for name in filenames:\n","    data = load_file(prefix + name)\n","    loaded.append(data)\n","  # stack group so that features are the 3rd dimension\n","  loaded = dstack(loaded)\n","  return loaded\n","\n","# load a dataset group, such as train or test\n","def load_dataset_group(group, prefix=''):\n","  filepath = prefix + '/' + group + '/Inertial Signals/'\n","  # load all 9 files as a single array\n","  filenames = list()\n","  # total acceleration\n","  filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n","  # body acceleration\n","  filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n","  # body gyroscope\n","  filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n","  # load input data\n","  X = load_group(filenames, filepath)\n","  # load class output\n","  # y = load_file(prefix + '/' + group + '/y_' + group + '.txt') # doesn't work with default 'utf-8'\n","  y = read_csv(prefix + '/' + group + '/y_' + group + '.txt', header=None, encoding='utf-16')\n","  return X, y\n","\n","# load the dataset, returns train and test X and y elements\n","def load_dataset(path=''):\n","  # print(path)\n","  # load all train\n","  trainX, trainy = load_dataset_group('train', path)\n","  # load all test\n","  testX, testy = load_dataset_group('test', path)\n","  # zero-offset class values\n","  trainy = trainy - 1\n","  testy = testy - 1\n","  # one hot encode y\n","  trainy = to_categorical(trainy)\n","  testy = to_categorical(testy)\n","  return trainX, trainy, testX, testy"],"metadata":{"id":"uDzbiEUNUsFD","executionInfo":{"status":"ok","timestamp":1697309074321,"user_tz":-180,"elapsed":8,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"execution_count":165,"outputs":[]},{"cell_type":"code","source":["# fit and evaluate a model\n","def evaluate_model(trainX, trainy, testX, testy):\n","  # define model\n","  verbose, epochs, batch_size = 0, 10, 32\n","  n_features, n_outputs = trainX.shape[2], trainy.shape[1]\n","  # reshape data into time steps of sub-sequences\n","  n_steps, n_length = 4, 32\n","  trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n","  testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n","  # define model hyperparameters\n","  dropout = 0.25 # default 0.5\n","  units = 100 # default 100\n","  dense_layer_nodes = 512 # default 100\n","  filter_size = 7 # default 3\n","  pool_size = 2 # default 2\n","  num_of_filters = 128 # default 64\n","  learning_rate = 0.001 # default 0.001 = 1e-3\n","  # define model\n","  model = Sequential()\n","  model.add(TimeDistributed(Conv1D(num_of_filters, filter_size, activation='relu'), input_shape=(None,n_length,n_features)))\n","  model.add(TimeDistributed(Conv1D(num_of_filters, filter_size, activation='relu')))\n","  model.add(TimeDistributed(Dropout(dropout)))\n","  model.add(TimeDistributed(MaxPooling1D(pool_size=pool_size)))\n","  model.add(TimeDistributed(Flatten()))\n","  model.add(LSTM(units, dropout=dropout))\n","  # model.add(Dropout(dropout))\n","  model.add(Dense(dense_layer_nodes, activation='relu'))\n","  model.add(Dense(n_outputs, activation='softmax'))\n","  opt = Adam(learning_rate=learning_rate)\n","  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","  # fit network\n","  model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n","  # evaluate model\n","  _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n","  return accuracy, model"],"metadata":{"id":"QtKPHmbqlLag","executionInfo":{"status":"ok","timestamp":1697309074321,"user_tz":-180,"elapsed":7,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"execution_count":166,"outputs":[]},{"cell_type":"code","source":["# summarize scores\n","def summarize_results(scores):\n","  print(scores)\n","  m, s = mean(scores), std(scores)\n","  print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"],"metadata":{"id":"5MaGZiMRlNDU","executionInfo":{"status":"ok","timestamp":1697309074321,"user_tz":-180,"elapsed":6,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"execution_count":167,"outputs":[]},{"cell_type":"code","source":["# run an experiment\n","def run_experiment(repeats=10, path=''):\n","  print(\"Experiment starting. Loading dataset...\")\n","  # load data\n","  trainX, trainy, testX, testy = load_dataset(path)\n","  print(\"Finished loading dataset, starting model training...\")\n","  # repeat experiment\n","  scores = list()\n","  for r in range(repeats):\n","    score, model = evaluate_model(trainX, trainy, testX, testy)\n","    score = score * 100.0\n","    print('>#%d: %.3f' % (r+1, score))\n","    scores.append(score)\n","  # summarize results\n","  summarize_results(scores)\n","  print(model.summary())"],"metadata":{"id":"Hmk-1poqlkeT","executionInfo":{"status":"ok","timestamp":1697309074321,"user_tz":-180,"elapsed":6,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"execution_count":168,"outputs":[]},{"cell_type":"code","source":["# run the experiment\n","run_experiment(path=path)"],"metadata":{"id":"RQdf0oelmYF9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cf94cd45-4df2-411f-afe7-f61774bf8dd1","executionInfo":{"status":"ok","timestamp":1697309256131,"user_tz":-180,"elapsed":181816,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"execution_count":169,"outputs":[{"output_type":"stream","name":"stdout","text":["Experiment starting. Loading dataset...\n","Finished loading dataset, starting model training...\n",">#1: 92.704\n",">#2: 91.619\n",">#3: 91.517\n",">#4: 91.517\n",">#5: 92.433\n",">#6: 90.397\n",">#7: 91.788\n",">#8: 89.990\n",">#9: 90.838\n",">#10: 91.076\n","[92.70444512367249, 91.6185975074768, 91.51679873466492, 91.51679873466492, 92.43298172950745, 90.39701223373413, 91.78826212882996, 89.98982310295105, 90.83814024925232, 91.07567071914673]\n","Accuracy: 91.388% (+/-0.801)\n","Model: \"sequential_192\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," time_distributed_960 (Time  (None, None, 26, 128)     8192      \n"," Distributed)                                                    \n","                                                                 \n"," time_distributed_961 (Time  (None, None, 20, 128)     114816    \n"," Distributed)                                                    \n","                                                                 \n"," time_distributed_962 (Time  (None, None, 20, 128)     0         \n"," Distributed)                                                    \n","                                                                 \n"," time_distributed_963 (Time  (None, None, 10, 128)     0         \n"," Distributed)                                                    \n","                                                                 \n"," time_distributed_964 (Time  (None, None, 1280)        0         \n"," Distributed)                                                    \n","                                                                 \n"," lstm_192 (LSTM)             (None, 100)               552400    \n","                                                                 \n"," dense_384 (Dense)           (None, 512)               51712     \n","                                                                 \n"," dense_385 (Dense)           (None, 6)                 3078      \n","                                                                 \n","=================================================================\n","Total params: 730198 (2.79 MB)\n","Trainable params: 730198 (2.79 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nfTgVOsCZKRx","executionInfo":{"status":"ok","timestamp":1697309256132,"user_tz":-180,"elapsed":18,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"execution_count":169,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}