{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"m_MSc4I6KvU4"},"outputs":[],"source":["from numpy import mean\n","from numpy import std\n","from numpy import dstack\n","from pandas import read_csv\n","from tensorflow import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FcDsa1dmf6an"},"outputs":[],"source":["# drive path\n","drive = '/content/drive/My Drive/Colab Notebooks/HAR'\n","\n","# local path\n","local = 'G:/My Drive/Colab Notebooks/HAR'\n","\n","hapt = '/HAPT Data Set'       # Human Activity Postural Transitions data set\n","har = '/UCI HAR Dataset'      # Human Activity Recognition data set\n","\n","path_drive = drive + har\n","path_local = local + har"]},{"cell_type":"code","source":["using_drive = 1\n","\n","if using_drive == 1:\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  path = path_drive\n","else:\n","  path = path_local"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZkEbaQgbWd0i","executionInfo":{"status":"ok","timestamp":1683209648333,"user_tz":-180,"elapsed":3145,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}},"outputId":"af05c0fd-134c-4cc8-9ede-86d112c96d48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Gravitational acceleration data files for x, y and z axes: `total_acc_x_train.txt`, `total_acc_y_train.txt` , `total_acc_z_train.txt`.<br>\n","Body acceleration data files for x, y and z axes: `body_acc_x_train.txt`, `body_acc_y_train.txt`, `body_acc_z_train.txt`.<br>\n","Body gyroscope data files for x, y and z axes: `body_gyro_x_train.txt`,\n","`body_gyro_y_train.txt`, `body_gyro_z_train.txt`.<br>\n","The structure is mirrored in the test directory."],"metadata":{"id":"SUg9w7CnY-Cw"}},{"cell_type":"code","source":["# load a single file as a numpy array\n","def load_file(filepath):\n","  dataframe = read_csv(filepath, header=None, delim_whitespace=True, encoding='utf-8', encoding_errors='ignore')\n","  return dataframe.values\n","\n","# load a list of files, such as x, y, z data for a given variable\n","def load_group(filenames, prefix=''):\n","  loaded = list()\n","  for name in filenames:\n","    data = load_file(prefix + name)\n","    loaded.append(data)\n","  # stack group so that features are the 3rd dimension\n","  loaded = dstack(loaded)\n","  return loaded\n","\n","# load a dataset group, such as train or test\n","def load_dataset_group(group, prefix=''):\n","  filepath = prefix + '/' + group + '/Inertial Signals/'\n","  # load all 9 files as a single array\n","  filenames = list()\n","  # total acceleration\n","  filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n","  # body acceleration\n","  filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n","  # body gyroscope\n","  filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n","  # load input data\n","  X = load_group(filenames, filepath)\n","  # load class output\n","  # y = load_file(prefix + '/' + group + '/y_' + group + '.txt') # doesn't work with default 'utf-8'\n","  y = read_csv(prefix + '/' + group + '/y_' + group + '.txt', header=None, encoding='utf-16')\n","  return X, y\n","\n","# load the dataset, returns train and test X and y elements\n","def load_dataset(path=''):\n","  # print(path)\n","  # load all train\n","  trainX, trainy = load_dataset_group('train', path)\n","  # load all test\n","  testX, testy = load_dataset_group('test', path)\n","  # zero-offset class values\n","  trainy = trainy - 1\n","  testy = testy - 1\n","  # one hot encode y\n","  trainy = to_categorical(trainy)\n","  testy = to_categorical(testy)\n","  return trainX, trainy, testX, testy"],"metadata":{"id":"uDzbiEUNUsFD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fit and evaluate a model\n","def evaluate_model(trainX, trainy, testX, testy):\n","  verbose, epochs, batch_size = 1, 10, 32\n","  n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n","  model = Sequential()\n","  model.add(Conv1D(64, 3, activation='relu', input_shape=(n_timesteps,n_features))) # filters=64, kernel_size=3 (length of the 1D convolution window)\n","  model.add(Conv1D(64, 3, activation='relu'))\n","  model.add(Dropout(0.5))\n","  model.add(AveragePooling1D()) # pool_size=2, strides=None, padding=\"valid\" (no padding), or \"same\" (results in padding evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input)\n","  model.add(Flatten())\n","  model.add(Dense(100, activation='relu'))\n","  model.add(Dense(n_outputs, activation='softmax'))\n","  opt = keras.optimizers.Adam(learning_rate=0.01) # default 0.001\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  # fit network\n","  model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=0)\n","  # evaluate model\n","  _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=verbose)\n","  return accuracy, model"],"metadata":{"id":"QtKPHmbqlLag"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# summarize scores\n","def summarize_results(scores):\n","  print(scores)\n","  m, s = mean(scores), std(scores)\n","  print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"],"metadata":{"id":"5MaGZiMRlNDU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run an experiment\n","def run_experiment(repeats=10, path=''):\n","  # load data\n","  trainX, trainy, testX, testy = load_dataset(path)\n","  # repeat experiment\n","  scores = list()\n","  for r in range(repeats):\n","    score, model = evaluate_model(trainX, trainy, testX, testy)\n","    score = score * 100.0\n","    print('>#%d: %.3f' % (r+1, score))\n","    scores.append(score)\n","  # summarize results\n","  summarize_results(scores)\n","  print(model.summary())"],"metadata":{"id":"Hmk-1poqlkeT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run the experiment\n","run_experiment(path=path)"],"metadata":{"id":"RQdf0oelmYF9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"245cb80a-3b05-4ed7-c6d7-0d7c549813af","executionInfo":{"status":"ok","timestamp":1683209787301,"user_tz":-180,"elapsed":138971,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/HAR/UCI HAR Dataset\n","93/93 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.9121\n",">#1: 91.211\n","93/93 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.9138\n",">#2: 91.381\n","93/93 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.9111\n",">#3: 91.110\n","93/93 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.9209\n",">#4: 92.094\n","93/93 [==============================] - 1s 4ms/step - loss: 0.6163 - accuracy: 0.9192\n",">#5: 91.924\n","93/93 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.9135\n",">#6: 91.347\n","93/93 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.9046\n",">#7: 90.465\n","93/93 [==============================] - 1s 4ms/step - loss: 0.7446 - accuracy: 0.8985\n",">#8: 89.854\n","93/93 [==============================] - 1s 4ms/step - loss: 0.4603 - accuracy: 0.8972\n",">#9: 89.718\n","93/93 [==============================] - 1s 4ms/step - loss: 0.7883 - accuracy: 0.9077\n",">#10: 90.770\n","[91.21140241622925, 91.3810670375824, 91.10960364341736, 92.09365248680115, 91.923987865448, 91.34713411331177, 90.46487808227539, 89.85409140586853, 89.71835970878601, 90.77027440071106]\n","Accuracy: 90.987% (+/-0.753)\n","Model: \"sequential_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv1d_18 (Conv1D)          (None, 126, 64)           1792      \n","                                                                 \n"," conv1d_19 (Conv1D)          (None, 124, 64)           12352     \n","                                                                 \n"," dropout_9 (Dropout)         (None, 124, 64)           0         \n","                                                                 \n"," average_pooling1d_9 (Averag  (None, 62, 64)           0         \n"," ePooling1D)                                                     \n","                                                                 \n"," flatten_9 (Flatten)         (None, 3968)              0         \n","                                                                 \n"," dense_18 (Dense)            (None, 100)               396900    \n","                                                                 \n"," dense_19 (Dense)            (None, 6)                 606       \n","                                                                 \n","=================================================================\n","Total params: 411,650\n","Trainable params: 411,650\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuClass":"premium"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}