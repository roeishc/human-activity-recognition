{"cells":[{"cell_type":"code","source":["from numpy import mean\n","from numpy import std\n","from numpy import dstack\n","from pandas import read_csv\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, LSTM, Bidirectional\n","from keras.utils import to_categorical\n","from keras.optimizers import Adam"],"metadata":{"id":"x04X16ZrTkfc","executionInfo":{"status":"ok","timestamp":1697291849413,"user_tz":-180,"elapsed":350,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"execution_count":145,"outputs":[]},{"cell_type":"code","execution_count":146,"metadata":{"id":"FcDsa1dmf6an","executionInfo":{"status":"ok","timestamp":1697291849781,"user_tz":-180,"elapsed":2,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"outputs":[],"source":["# drive path\n","drive = '/content/drive/My Drive/Colab Notebooks/HAR'\n","\n","# local path\n","# local = 'G:/My Drive/Colab Notebooks/HAR'\n","local = 'G:/HAR'\n","\n","hapt = '/HAPT Dataset'       # Human Activity Postural Transitions data set\n","har = '/UCI HAR Dataset'      # Human Activity Recognition data set\n","\n","path_drive = drive + har\n","path_local = local + har"]},{"cell_type":"code","source":["using_drive = 1\n","\n","if using_drive == 1:\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  path = path_drive\n","else:\n","  path = path_local"],"metadata":{"id":"ZkEbaQgbWd0i","executionInfo":{"status":"ok","timestamp":1697291852559,"user_tz":-180,"elapsed":2780,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e6f44397-2c12-4ea7-b83c-0f87affed21b"},"execution_count":147,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Gravitational acceleration data files for x, y and z axes: `total_acc_x_train.txt`, `total_acc_y_train.txt` , `total_acc_z_train.txt`.<br>\n","Body acceleration data files for x, y and z axes: `body_acc_x_train.txt`, `body_acc_y_train.txt`, `body_acc_z_train.txt`.<br>\n","Body gyroscope data files for x, y and z axes: `body_gyro_x_train.txt`,\n","`body_gyro_y_train.txt`, `body_gyro_z_train.txt`.<br>\n","The structure is mirrored in the test directory."],"metadata":{"id":"SUg9w7CnY-Cw"}},{"cell_type":"code","source":["# load a single file as a numpy array\n","def load_file(filepath):\n","  dataframe = read_csv(filepath, header=None, delim_whitespace=True, encoding='utf-8', encoding_errors='ignore')\n","  return dataframe.values\n","\n","# load a list of files, such as x, y, z data for a given variable\n","def load_group(filenames, prefix=''):\n","  loaded = list()\n","  for name in filenames:\n","    data = load_file(prefix + name)\n","    loaded.append(data)\n","  # stack group so that features are the 3rd dimension\n","  loaded = dstack(loaded)\n","  return loaded\n","\n","# load a dataset group, such as train or test\n","def load_dataset_group(group, prefix=''):\n","  filepath = prefix + '/' + group + '/Inertial Signals/'\n","  # load all 9 files as a single array\n","  filenames = list()\n","  # total acceleration\n","  filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n","  # body acceleration\n","  filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n","  # body gyroscope\n","  filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n","  # load input data\n","  X = load_group(filenames, filepath)\n","  # load class output\n","  # y = load_file(prefix + '/' + group + '/y_' + group + '.txt') # doesn't work with default 'utf-8'\n","  y = read_csv(prefix + '/' + group + '/y_' + group + '.txt', header=None, encoding='utf-16')\n","  return X, y\n","\n","# load the dataset, returns train and test X and y elements\n","def load_dataset(path=''):\n","  # print(path)\n","  # load all train\n","  trainX, trainy = load_dataset_group('train', path)\n","  # load all test\n","  testX, testy = load_dataset_group('test', path)\n","  # zero-offset class values\n","  trainy = trainy - 1\n","  testy = testy - 1\n","  # one hot encode y\n","  trainy = to_categorical(trainy)\n","  testy = to_categorical(testy)\n","  return trainX, trainy, testX, testy"],"metadata":{"id":"uDzbiEUNUsFD","executionInfo":{"status":"ok","timestamp":1697291852559,"user_tz":-180,"elapsed":6,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"execution_count":148,"outputs":[]},{"cell_type":"code","source":["# fit and evaluate a model\n","def evaluate_model(trainX, trainy, testX, testy):\n","  verbose, epochs, batch_size = 0, 10, 32 # default 0, 10, 32\n","  n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n","  dropout = 0.75 # default 0.5\n","  units = 100 # default 100\n","  dense_layer_nodes = 100 # default 100\n","  model = Sequential()\n","  model.add(Bidirectional(LSTM(64, return_sequences=True, dropout=dropout), input_shape=(n_timesteps,n_features)))\n","  model.add(Bidirectional(LSTM(32)))\n","  # model.add(LSTM(units, input_shape=(n_timesteps,n_features)))\n","  # model.add(Dropout(dropout))\n","  model.add(Dense(dense_layer_nodes, activation='relu'))\n","  model.add(Dense(n_outputs, activation='softmax'))\n","  opt = Adam(learning_rate=0.001) # default 0.001 = 1e-3\n","  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","  # fit network\n","  model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n","  # evaluate model\n","  _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n","  return accuracy, model"],"metadata":{"id":"QtKPHmbqlLag","executionInfo":{"status":"ok","timestamp":1697291852559,"user_tz":-180,"elapsed":5,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"execution_count":149,"outputs":[]},{"cell_type":"code","source":["# summarize scores\n","def summarize_results(scores):\n","  print(scores)\n","  m, s = mean(scores), std(scores)\n","  print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"],"metadata":{"id":"5MaGZiMRlNDU","executionInfo":{"status":"ok","timestamp":1697291852559,"user_tz":-180,"elapsed":5,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"execution_count":150,"outputs":[]},{"cell_type":"code","source":["# run an experiment\n","def run_experiment(repeats=10, path=''):\n","  print(\"Experiment starting. Loading dataset...\")\n","  # load data\n","  trainX, trainy, testX, testy = load_dataset(path)\n","  print(\"Finished loading dataset, starting model training...\")\n","  # repeat experiment\n","  scores = list()\n","  for r in range(repeats):\n","    score, model = evaluate_model(trainX, trainy, testX, testy)\n","    score = score * 100.0\n","    print('>#%d: %.3f' % (r+1, score))\n","    scores.append(score)\n","  # summarize results\n","  summarize_results(scores)\n","  print(model.summary())"],"metadata":{"id":"Hmk-1poqlkeT","executionInfo":{"status":"ok","timestamp":1697291852559,"user_tz":-180,"elapsed":5,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"execution_count":151,"outputs":[]},{"cell_type":"code","source":["# run the experiment\n","run_experiment(path=path)"],"metadata":{"id":"RQdf0oelmYF9","executionInfo":{"status":"ok","timestamp":1697292625855,"user_tz":-180,"elapsed":773300,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0de8c14e-bd88-4a7f-8844-d16a000437f1"},"execution_count":152,"outputs":[{"output_type":"stream","name":"stdout","text":["Experiment starting. Loading dataset...\n","Finished loading dataset, starting model training...\n",">#1: 89.888\n",">#2: 86.495\n",">#3: 88.327\n",">#4: 88.191\n",">#5: 88.938\n",">#6: 81.303\n",">#7: 71.768\n",">#8: 86.020\n",">#9: 85.103\n",">#10: 75.365\n","[89.88802433013916, 86.49473786354065, 88.32710981369019, 88.19137811660767, 88.93790245056152, 81.30301833152771, 71.76790237426758, 86.01968288421631, 85.1034939289093, 75.36478042602539]\n","Accuracy: 84.140% (+/-5.815)\n","Model: \"sequential_113\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," bidirectional_219 (Bidirec  (None, 128, 128)          37888     \n"," tional)                                                         \n","                                                                 \n"," bidirectional_220 (Bidirec  (None, 64)                41216     \n"," tional)                                                         \n","                                                                 \n"," dense_209 (Dense)           (None, 100)               6500      \n","                                                                 \n"," dense_210 (Dense)           (None, 6)                 606       \n","                                                                 \n","=================================================================\n","Total params: 86210 (336.76 KB)\n","Trainable params: 86210 (336.76 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nfTgVOsCZKRx","executionInfo":{"status":"ok","timestamp":1697292625855,"user_tz":-180,"elapsed":12,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"}}},"execution_count":152,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}