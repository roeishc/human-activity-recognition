{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3394,"status":"ok","timestamp":1697394714393,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"},"user_tz":-180},"id":"x04X16ZrTkfc"},"outputs":[],"source":["from numpy import mean, std, dstack\n","from pandas import read_csv\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, Dropout, ConvLSTM2D\n","from keras.utils import to_categorical\n","from keras.optimizers import Adam"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1697394714393,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"},"user_tz":-180},"id":"FcDsa1dmf6an"},"outputs":[],"source":["# drive path\n","drive = '/content/drive/My Drive/Colab Notebooks/HAR'\n","\n","# local path\n","# local = 'G:/My Drive/Colab Notebooks/HAR'\n","local = 'G:/HAR'\n","\n","hapt = '/HAPT Dataset'       # Human Activity Postural Transitions data set\n","har = '/UCI HAR Dataset'      # Human Activity Recognition data set\n","\n","path_drive = drive + har\n","path_local = local + har"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19018,"status":"ok","timestamp":1697394733408,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"},"user_tz":-180},"id":"ZkEbaQgbWd0i","outputId":"e80a73c2-21b2-4013-efdc-e42f8bb3e006"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["using_drive = 1\n","\n","if using_drive == 1:\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  path = path_drive\n","else:\n","  path = path_local"]},{"cell_type":"markdown","metadata":{"id":"SUg9w7CnY-Cw"},"source":["Gravitational acceleration data files for x, y and z axes: `total_acc_x_train.txt`, `total_acc_y_train.txt` , `total_acc_z_train.txt`.\u003cbr\u003e\n","Body acceleration data files for x, y and z axes: `body_acc_x_train.txt`, `body_acc_y_train.txt`, `body_acc_z_train.txt`.\u003cbr\u003e\n","Body gyroscope data files for x, y and z axes: `body_gyro_x_train.txt`,\n","`body_gyro_y_train.txt`, `body_gyro_z_train.txt`.\u003cbr\u003e\n","The structure is mirrored in the test directory."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1697394733408,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"},"user_tz":-180},"id":"uDzbiEUNUsFD"},"outputs":[],"source":["# load a single file as a numpy array\n","def load_file(filepath):\n","  dataframe = read_csv(filepath, header=None, delim_whitespace=True, encoding='utf-8', encoding_errors='ignore')\n","  return dataframe.values\n","\n","# load a list of files, such as x, y, z data for a given variable\n","def load_group(filenames, prefix=''):\n","  loaded = list()\n","  for name in filenames:\n","    data = load_file(prefix + name)\n","    loaded.append(data)\n","  # stack group so that features are the 3rd dimension\n","  loaded = dstack(loaded)\n","  return loaded\n","\n","# load a dataset group, such as train or test\n","def load_dataset_group(group, prefix=''):\n","  filepath = prefix + '/' + group + '/Inertial Signals/'\n","  # load all 9 files as a single array\n","  filenames = list()\n","  # total acceleration\n","  filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n","  # body acceleration\n","  filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n","  # body gyroscope\n","  filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n","  # load input data\n","  X = load_group(filenames, filepath)\n","  # load class output\n","  # y = load_file(prefix + '/' + group + '/y_' + group + '.txt') # doesn't work with default 'utf-8'\n","  y = read_csv(prefix + '/' + group + '/y_' + group + '.txt', header=None, encoding='utf-16')\n","  return X, y\n","\n","# load the dataset, returns train and test X and y elements\n","def load_dataset(path=''):\n","  # print(path)\n","  # load all train\n","  trainX, trainy = load_dataset_group('train', path)\n","  # load all test\n","  testX, testy = load_dataset_group('test', path)\n","  # zero-offset class values\n","  trainy = trainy - 1\n","  testy = testy - 1\n","  # one hot encode y\n","  trainy = to_categorical(trainy)\n","  testy = to_categorical(testy)\n","  return trainX, trainy, testX, testy"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1697394733408,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"},"user_tz":-180},"id":"QtKPHmbqlLag"},"outputs":[],"source":["# fit and evaluate a model\n","def evaluate_model(trainX, trainy, testX, testy):\n","  # define model\n","  verbose, epochs, batch_size = 0, 10, 32\n","  n_features, n_outputs = trainX.shape[2], trainy.shape[1]\n","  # reshape into subsequences (samples, time steps, rows, cols, channels)\n","  n_steps, n_length = 4, 32\n","  trainX = trainX.reshape((trainX.shape[0], n_steps, 1, n_length, n_features))\n","  testX = testX.reshape((testX.shape[0], n_steps, 1, n_length, n_features))\n","  # define hyperparameters\n","  num_of_filters = 128 # default 64\n","  filter_size = (1,3) # default (1,3)\n","  dropout = 0.5 # default 0.5\n","  dense_layer_nodes = 100 # default 100\n","  learning_rate = 0.001 # default 0.001 = 1e-3\n","  # define model\n","  model = Sequential()\n","  model.add(ConvLSTM2D(num_of_filters, filter_size, activation='relu', input_shape=(n_steps, 1, n_length, n_features), dropout=dropout))\n","  model.add(Flatten())\n","  model.add(Dense(dense_layer_nodes, activation='relu'))\n","  model.add(Dropout(dropout))\n","  model.add(Dense(n_outputs, activation='softmax'))\n","  opt = Adam(learning_rate=learning_rate)\n","  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","  # fit network\n","  model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n","  # evaluate model\n","  _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n","  return accuracy, model"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1697394733408,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"},"user_tz":-180},"id":"5MaGZiMRlNDU"},"outputs":[],"source":["# summarize scores\n","def summarize_results(scores):\n","  print(scores)\n","  m, s = mean(scores), std(scores)\n","  print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1697394733408,"user":{"displayName":"Roei Shchory","userId":"04749280811829986005"},"user_tz":-180},"id":"Hmk-1poqlkeT"},"outputs":[],"source":["# run an experiment\n","def run_experiment(repeats=10, path=''):\n","  print(\"Experiment starting. Loading dataset...\")\n","  # load data\n","  trainX, trainy, testX, testy = load_dataset(path)\n","  print(\"Finished loading dataset, starting model training...\")\n","  # repeat experiment\n","  scores = list()\n","  for r in range(repeats):\n","    score, model = evaluate_model(trainX, trainy, testX, testy)\n","    score = score * 100.0\n","    print('\u003e#%d: %.3f' % (r+1, score))\n","    scores.append(score)\n","  # summarize results\n","  summarize_results(scores)\n","  print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"RQdf0oelmYF9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Experiment starting. Loading dataset...\n","Finished loading dataset, starting model training...\n","\u003e#1: 90.159\n","\u003e#2: 90.329\n","\u003e#3: 89.650\n","\u003e#4: 90.567\n","\u003e#5: 92.501\n","\u003e#6: 90.499\n","\u003e#7: 91.551\n","\u003e#8: 86.970\n","\u003e#9: 91.619\n","\u003e#10: 90.567\n","[90.15948176383972, 90.32914638519287, 89.65049386024475, 90.56667685508728, 92.5008475780487, 90.49881100654602, 91.55073165893555, 86.96979880332947, 91.6185975074768, 90.56667685508728]\n","Accuracy: 90.441% (+/-1.402)\n","Model: \"sequential_19\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv_lstm2d_19 (ConvLSTM2D  (None, 1, 30, 128)        210944    \n"," )                                                               \n","                                                                 \n"," flatten_19 (Flatten)        (None, 3840)              0         \n","                                                                 \n"," dense_38 (Dense)            (None, 100)               384100    \n","                                                                 \n"," dropout_19 (Dropout)        (None, 100)               0         \n","                                                                 \n"," dense_39 (Dense)            (None, 6)                 606       \n","                                                                 \n","=================================================================\n","Total params: 595650 (2.27 MB)\n","Trainable params: 595650 (2.27 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}],"source":["# run the experiment\n","run_experiment(path=path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nfTgVOsCZKRx"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}